{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x10221b470>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, DateType\n",
    "import datetime, math\n",
    "\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x10522ce48>\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Catch you merchant\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"/opt/jupyter_workspace/spark-warehouse\")\n",
    "         .getOrCreate())\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace = \"/Users/AUM/Desktop/MerchantInsight/mock_data/\"\n",
    "\n",
    "df = (spark\n",
    "     .read\n",
    "     .option(\"header\", \"true\")\n",
    "     .option(\"inferSchema\", \"true\")\n",
    "     .csv(workspace + \"deposit_mock.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+\n",
      "|ar_id|fm_to_ar_id|txn_amt|svc_br_no|opm_tp_cd|txn_cd|ptn_yyyy|ptn_mm|ptn_dd|  txn_tm|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3| 5:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3| 5:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|11:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|11:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3|17:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3|17:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|23:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|23:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3| 5:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3| 5:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     3|11:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     3|11:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3|17:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3|17:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     3|23:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     3|23:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     4| 5:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     4| 5:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     4|11:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     4|11:00:00|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define useful variable\n",
    "\n",
    "number_of_months = 10\n",
    "transfer_code = 0\n",
    "deposit_code = 2\n",
    "withdraw_code = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "|ar_id|fm_to_ar_id|txn_amt|svc_br_no|opm_tp_cd|txn_cd|ptn_yyyy|ptn_mm|ptn_dd|  txn_tm|      date|day_of_week|day_of_week_code|quarter_code|period_code|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3| 5:00:00|2017-01-03|          1|               0|           1|          0|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3| 5:00:00|2017-01-03|          1|               0|           1|          0|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|11:00:00|2017-01-03|          1|               0|           1|          1|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|11:00:00|2017-01-03|          1|               0|           1|          1|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3|17:00:00|2017-01-03|          1|               0|           1|          2|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3|17:00:00|2017-01-03|          1|               0|           1|          2|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|23:00:00|2017-01-03|          1|               0|           1|          3|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|23:00:00|2017-01-03|          1|               0|           1|          3|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3| 5:00:00|2017-03-03|          4|               1|           1|          0|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3| 5:00:00|2017-03-03|          4|               1|           1|          0|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     3|11:00:00|2017-03-03|          4|               1|           1|          1|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     3|11:00:00|2017-03-03|          4|               1|           1|          1|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3|17:00:00|2017-03-03|          4|               1|           1|          2|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3|17:00:00|2017-03-03|          4|               1|           1|          2|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     3|23:00:00|2017-03-03|          4|               1|           1|          3|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     3|23:00:00|2017-03-03|          4|               1|           1|          3|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     4| 5:00:00|2017-03-04|          5|               2|           1|          0|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     4| 5:00:00|2017-03-04|          5|               2|           1|          0|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     4|11:00:00|2017-03-04|          5|               2|           1|          1|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     4|11:00:00|2017-03-04|          5|               2|           1|          1|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-organize the original data set\n",
    "\n",
    "def no_days_in_month(month, year):\n",
    "    if month in day_months_31: \n",
    "        return 31\n",
    "    elif month in day_months_30:\n",
    "        return 30\n",
    "    else:\n",
    "        if calendar.isleap(year):\n",
    "            return 29\n",
    "        else:\n",
    "            return 28\n",
    "        \n",
    "def day_of_week_code(day_of_week):\n",
    "    if day_of_week < 4:\n",
    "        return 0\n",
    "    elif day_of_week > 4:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def quarter_code(date, month):\n",
    "    month_31_days = [1,3,5,7,8,10,12]\n",
    "    month_30_days = [4,6,9,11]\n",
    "    if(month in month_31_days):\n",
    "        if(date in range(1,9)):\n",
    "            return 1\n",
    "        elif(date in range(9,16)):\n",
    "            return 2\n",
    "        elif(date in range(16,24)):\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    elif(month in month_30_days):\n",
    "        if(date in range(1,9)):\n",
    "            return 1\n",
    "        elif(date in range(9,16)):\n",
    "            return 2\n",
    "        elif(date in range(16,23)):\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    else: # February\n",
    "        return math.ceil(date / 4.0) \n",
    "\n",
    "def period_code(time):\n",
    "    hour = int(time[:-6])\n",
    "    if hour in range(0, 6):\n",
    "        return 0\n",
    "    elif hour in range(6, 12):\n",
    "        return 1\n",
    "    elif hour in range(12, 18):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "date = udf(lambda y, m, d : datetime.datetime(y, m ,d), DateType())\n",
    "day_of_week = udf(lambda date : int(date.weekday()), IntegerType())\n",
    "day_of_week_code_udf = udf(day_of_week_code, IntegerType())\n",
    "quarter_code_udf = udf(quarter_code, IntegerType())\n",
    "period_code_udf = udf(period_code, IntegerType())\n",
    "\n",
    "df = df.withColumn(\"date\", date(df[\"ptn_yyyy\"], df[\"ptn_mm\"], df[\"ptn_dd\"]))\n",
    "df = df.withColumn(\"day_of_week\", day_of_week(df[\"date\"]))\n",
    "df = df.withColumn(\"day_of_week_code\", day_of_week_code_udf(df[\"day_of_week\"]))\n",
    "df = df.withColumn(\"quarter_code\", quarter_code_udf(df[\"ptn_dd\"], df[\"ptn_mm\"]))\n",
    "df = df.withColumn(\"period_code\", period_code_udf(df[\"txn_tm\"]))\n",
    "\n",
    "\n",
    "# df = df.select(\"ar_id\", \"fm_to_ar_id\", \"txn_amt\", \"svc_br_no\", \"opm_tp_cd\", \"txn_cd\", \"day_of_week_code\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "|ar_id|fm_to_ar_id|txn_amt|svc_br_no|opm_tp_cd|txn_cd|ptn_yyyy|ptn_mm|ptn_dd|  txn_tm|      date|day_of_week|day_of_week_code|quarter_code|period_code|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3| 5:00:00|2017-01-03|          1|               0|           1|          0|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3| 5:00:00|2017-01-03|          1|               0|           1|          0|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|11:00:00|2017-01-03|          1|               0|           1|          1|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|11:00:00|2017-01-03|          1|               0|           1|          1|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3|17:00:00|2017-01-03|          1|               0|           1|          2|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3|17:00:00|2017-01-03|          1|               0|           1|          2|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|23:00:00|2017-01-03|          1|               0|           1|          3|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|23:00:00|2017-01-03|          1|               0|           1|          3|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3| 5:00:00|2017-03-03|          4|               1|           1|          0|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3| 5:00:00|2017-03-03|          4|               1|           1|          0|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|ar_id|\n",
      "+-----+\n",
      "|    B|\n",
      "|    A|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define all users\n",
    "\n",
    "user_data = df.select(\"ar_id\").distinct().union(df.select(\"fm_to_ar_id\").distinct()).distinct()\n",
    "user_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define feature extraction functions\n",
    "\n",
    "def noDepositBranchVisit(is_unique):\n",
    "    if (is_unique):\n",
    "        return df.select(\"ar_id\", \"svc_br_no\").groupby(\"ar_id\").agg({\"svc_br_no\" : \"count\"}).withColumnRenamed(\"count(svc_br_no)\", \"noDepositBranchVisit\")\n",
    "    else:\n",
    "        return df.select(\"ar_id\", \"svc_br_no\").distinct().groupby(\"ar_id\").agg({\"svc_br_no\" : \"count\"}).withColumnRenamed(\"count(svc_br_no)\", \"noDepositBranchVisitUnique\")\n",
    "    \n",
    "def noDepositTransferIn(is_unique):\n",
    "    if (is_unique):\n",
    "        return df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").groupby([\"ar_id\", \"fm_to_ar_id\"]).agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"noDepositTransferInUnique\")\n",
    "    else:\n",
    "        return df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"noDepositTransferIn\")\n",
    "    \n",
    "def noDepositTransferOut(is_unique):\n",
    "    if (is_unique):\n",
    "        return df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").groupby([\"ar_id\", \"fm_to_ar_id\"]).agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"noDepositTransferOutUniqie\")\n",
    "    else:\n",
    "        return df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"noDepositTransferOut\")\n",
    "\n",
    "def noDeposit(): \n",
    "    # return df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"noDeposit\")\n",
    "    return df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\")\\\n",
    "            .groupby(\"ar_id\", \"quarter_code\").agg({\"*\" : \"count\"})\\\n",
    "            .withColumnRenamed(\"count(1)\", \"noDeposit\")\\\n",
    "            .crosstab(\"ar_id\", \"quarter_code\")\\\n",
    "            .toDF('ar_id','noDepositQ1','noDepositQ2','noDepositQ3','noDepositQ4')\n",
    "def noWithdraw(): \n",
    "    # return df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"noWithdraw\")\n",
    "    return df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\")\\\n",
    "            .groupby(\"ar_id\", \"quarter_code\").agg({\"*\" : \"count\"})\\\n",
    "            .withColumnRenamed(\"count(1)\", \"noWithdraw\")\\\n",
    "            .crosstab(\"ar_id\", \"quarter_code\")\\\n",
    "            .toDF('ar_id','noWithdrawQ1','noWithdrawQ2','noWithdrawQ3','noWithdrawQ4')\n",
    "def depositAmount(): \n",
    "    return df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"depositAmount\")\n",
    "\n",
    "def withdrawAmount(): \n",
    "    return df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"withdrawAmount\")\n",
    "\n",
    "def transferInAmount():\n",
    "    return df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"transferInAmount\")\n",
    "    \n",
    "def transferOutAmount():\n",
    "    return df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"transferOutAmount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define udf functions for all about ratio\n",
    "ratioDepositBranchVisit = udf(lambda visit, unique_visit : visit / unique_visit)\n",
    "ratioTransferIn = udf(lambda transfer_in, transfer_in_unique : transfer_in / transfer_in_unique)\n",
    "ratioTransferOut = udf(lambda transfer_out, transfer_out_unique : transfer_out / transfer_out_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+---------------+---------------+---------------+---------------+\n",
      "|ar_id|allDepositAmount|depositAmountQ1|depositAmountQ2|depositAmountQ3|depositAmountQ4|\n",
      "+-----+----------------+---------------+---------------+---------------+---------------+\n",
      "|    A|            2190|           1760|            210|            200|             20|\n",
      "+-----+----------------+---------------+---------------+---------------+---------------+\n",
      "\n",
      "+-----+----------------+---------------+---------------+---------------+---------------+\n",
      "|ar_id|allDepositAmount|depositAmountQ1|depositAmountQ2|depositAmountQ3|depositAmountQ4|\n",
      "+-----+----------------+---------------+---------------+---------------+---------------+\n",
      "|    A|            2190|           1760|            210|            200|             20|\n",
      "+-----+----------------+---------------+---------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quarter code example\n",
    "\n",
    "def get_df_with_quarter_code(data, col_name, agg_func, agg_col):\n",
    "    if agg_func == \"sum\":\n",
    "        return data.groupby(\"ar_id\").agg({agg_col : \"sum\"})\\\n",
    "                .withColumnRenamed(agg_func + '(' + agg_col + ')', \"all\" + col_name[0].upper() + col_name[1:])\\\n",
    "                .join(data.groupby(\"ar_id\").pivot(\"quarter_code\").sum(agg_col)\\\n",
    "                .toDF('ar_id', col_name + 'Q1', col_name + 'Q2', col_name + 'Q3', col_name + 'Q4'), \"ar_id\")\n",
    "    else :\n",
    "        return data.groupby(\"ar_id\").agg({agg_col : \"count\"})\\\n",
    "                .withColumnRenamed(\"count(1)\", \"all\" + col_name[0].upper() + col_name[1:])\\\n",
    "                .join(data.groupby(\"ar_id\").pivot(\"quarter_code\").count()\\\n",
    "                .toDF('ar_id', col_name + 'Q1', col_name + 'Q2', col_name + 'Q3', col_name + 'Q4'), \"ar_id\")\n",
    "\n",
    "data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 2\")\n",
    "\n",
    "# data.groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"})\\\n",
    "# .withColumnRenamed(\"sum(txn_amt)\", \"allDepositAmount\").show()\n",
    "\n",
    "# data.groupby([\"ar_id\", \"quarter_code\"]).agg({\"txn_amt\" : \"sum\"})\\\n",
    "# .withColumnRenamed(\"sum(txn_amt)\", \"depositAmount\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\").pivot(\"quarter_code\").sum(\"txn_amt\")\\\n",
    "# .toDF('ar_id', 'depositAmountQ1', 'depositAmountQ2', 'depositAmountQ3', 'depositAmountQ4').show()\n",
    "\n",
    "get_df_with_quarter_code(data, \"depositAmount\", \"sum\", \"txn_amt\").show()\n",
    "\n",
    "data.groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"})\\\n",
    ".withColumnRenamed(\"sum(txn_amt)\", \"allDepositAmount\")\\\n",
    ".join(data.groupby(\"ar_id\").pivot(\"quarter_code\").sum(\"txn_amt\")\\\n",
    ".toDF('ar_id', 'depositAmountQ1', 'depositAmountQ2', 'depositAmountQ3', 'depositAmountQ4'), \"ar_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-----------+-----------+-----------+-----------+\n",
      "|ar_id|allNoDeposit|noDepositP1|noDepositP2|noDepositP3|noDepositP4|\n",
      "+-----+------------+-----------+-----------+-----------+-----------+\n",
      "|    A|          39|          9|         10|         10|         10|\n",
      "+-----+------------+-----------+-----------+-----------+-----------+\n",
      "\n",
      "+-----+------------+-----------+-----------+-----------+-----------+\n",
      "|ar_id|allNoDeposit|noDepositP1|noDepositP2|noDepositP3|noDepositP4|\n",
      "+-----+------------+-----------+-----------+-----------+-----------+\n",
      "|    A|          39|          9|         10|         10|         10|\n",
      "+-----+------------+-----------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Period code example\n",
    "\n",
    "def get_df_with_period_code(data, col_name, agg_func, agg_col):\n",
    "    if agg_func == \"sum\":\n",
    "        return data.groupby(\"ar_id\").agg({agg_col : \"sum\"})\\\n",
    "                .withColumnRenamed(agg_func + '(' + agg_col + ')', \"all\" + col_name[0].upper() + col_name[1:])\\\n",
    "                .join(data.groupby(\"ar_id\").pivot(\"period_code\").sum(agg_col)\\\n",
    "                .toDF('ar_id', col_name + 'P1', col_name + 'P2', col_name + 'P3', col_name + 'P4'), \"ar_id\")\n",
    "    else :\n",
    "        return data.groupby(\"ar_id\").agg({agg_col : \"count\"})\\\n",
    "                .withColumnRenamed(\"count(1)\", \"all\" + col_name[0].upper() + col_name[1:])\\\n",
    "                .join(data.groupby(\"ar_id\").pivot(\"period_code\").count()\\\n",
    "                .toDF('ar_id', col_name + 'P1', col_name + 'P2', col_name + 'P3', col_name + 'P4'), \"ar_id\")\n",
    "\n",
    "data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 2\")\n",
    "\n",
    "# data.groupby(\"ar_id\").agg({\"*\" : \"count\"})\\\n",
    "# .withColumnRenamed(\"count(1)\", \"allNoDeposit\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\", \"period_code\").agg({\"*\" : \"count\"})\\\n",
    "# .withColumnRenamed(\"count(1)\", \"noDeposit\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\").pivot(\"period_code\").count()\\\n",
    "# .toDF('ar_id', 'noDepositQ1', 'noDepositQ2', 'noDepositQ3', 'noDepositQ4').show()\n",
    "\n",
    "get_df_with_period_code(data, \"noDeposit\", \"count\", \"*\").show()\n",
    "\n",
    "data.groupby(\"ar_id\").agg({\"*\" : \"count\"})\\\n",
    ".withColumnRenamed(\"count(1)\", \"allNoDeposit\")\\\n",
    ".join(data.groupby(\"ar_id\").pivot(\"period_code\").count()\\\n",
    ".toDF('ar_id', 'noDepositP1', 'noDepositP2', 'noDepositP3', 'noDepositP4'), \"ar_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monthly example\n",
    "## Find oldest & youngest Datetime object\n",
    "from pyspark.sql.functions import from_unixtime, unix_timestamp, min, max\n",
    "\n",
    "str_to_date = udf(lambda date_str : datetime.datetime.strptime(date_str[:-12], \"%Y-%m\"), DateType()) # ignore time & date\n",
    "get_user_number_of_month = udf(lambda oldest, youngest : (youngest.year - oldest.year) * 12 + (youngest.month - oldest.month) + 1, IntegerType())\n",
    "\n",
    "\n",
    "def get_user_number_of_month(user_df):\n",
    "user_df = df.select(\"ar_id\", \"date\").withColumn(\"unix_date\", unix_timestamp(\"date\")).groupby(\"ar_id\").agg(\n",
    "            from_unixtime(min(\"unix_date\")).alias(\"min_date\"), \n",
    "            from_unixtime(max(\"unix_date\")).alias(\"max_date\"))\n",
    "\n",
    "# user_df.show()\n",
    "\n",
    "user_df = user_df.withColumn(\"oldest_month\", str_to_date(user_df[\"min_date\"]))\n",
    "user_df = user_df.withColumn(\"youngest_month\", str_to_date(user_df[\"max_date\"]))\n",
    "user_df = user_df.withColumn(\"user_number_of_month\", get_user_number_of_month(user_df[\"oldest_month\"], user_df[\"youngest_month\"]))\n",
    "\n",
    "# user_df.show()\n",
    "\n",
    "return user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(date_df.select(\"min_date\").collect()[0].min_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|ar_id|depositAmount|\n",
      "+-----+-------------+\n",
      "|  13c|           10|\n",
      "|  11a|          100|\n",
      "|  12b|       205000|\n",
      "+-----+-------------+\n",
      "\n",
      "+-----+-------------+\n",
      "|ar_id|depositAmount|\n",
      "+-----+-------------+\n",
      "|  13c|           10|\n",
      "|  11a|          100|\n",
      "|  12b|       205000|\n",
      "|  16d|         null|\n",
      "|  15c|         null|\n",
      "|  14d|         null|\n",
      "|  13c|           10|\n",
      "|  11b|         null|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join section\n",
    "\n",
    "user_data.join(depositAmount(), \"ar_id\", \"left_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
