{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x10112a470>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, DateType\n",
    "import datetime, math\n",
    "\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x105104e48>\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Catch you merchant\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"/opt/jupyter_workspace/spark-warehouse\")\n",
    "         .getOrCreate())\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace = \"/Users/AUM/Desktop/MerchantInsight/mock_data/\"\n",
    "\n",
    "df = (spark\n",
    "     .read\n",
    "     .option(\"header\", \"true\")\n",
    "     .option(\"inferSchema\", \"true\")\n",
    "     .csv(workspace + \"deposit_mock.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+\n",
      "|ar_id|fm_to_ar_id|txn_amt|svc_br_no|opm_tp_cd|txn_cd|ptn_yyyy|ptn_mm|ptn_dd|  txn_tm|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3| 5:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3| 5:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|11:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|11:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3|17:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3|17:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|23:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|23:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3| 5:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3| 5:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     3|11:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     3|11:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3|17:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3|17:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     3|23:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     3|23:00:00|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     4| 5:00:00|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     4| 5:00:00|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     3|     4|11:00:00|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     3|     4|11:00:00|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define useful variable\n",
    "\n",
    "number_of_months = 10\n",
    "transfer_code = 0\n",
    "deposit_code = 2\n",
    "withdraw_code = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "|ar_id|fm_to_ar_id|txn_amt|svc_br_no|opm_tp_cd|txn_cd|ptn_yyyy|ptn_mm|ptn_dd|  txn_tm|      date|day_of_week|day_of_week_code|quarter_code|period_code|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3| 5:00:00|2017-01-03|          1|               1|           1|          1|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3| 5:00:00|2017-01-03|          1|               1|           1|          1|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|11:00:00|2017-01-03|          1|               1|           1|          2|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|11:00:00|2017-01-03|          1|               1|           1|          2|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     1|     3|17:00:00|2017-01-03|          1|               1|           1|          3|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     1|     3|17:00:00|2017-01-03|          1|               1|           1|          3|\n",
      "|    A|          B|    100|      900|       CR|     0|    2017|     1|     3|23:00:00|2017-01-03|          1|               1|           1|          4|\n",
      "|    B|          A|    100|      900|       DR|     0|    2017|     1|     3|23:00:00|2017-01-03|          1|               1|           1|          4|\n",
      "|    A|          B|     10|      900|       DR|     0|    2017|     3|     3| 5:00:00|2017-03-03|          4|               2|           1|          1|\n",
      "|    B|          A|     10|      900|       CR|     0|    2017|     3|     3| 5:00:00|2017-03-03|          4|               2|           1|          1|\n",
      "+-----+-----------+-------+---------+---------+------+--------+------+------+--------+----------+-----------+----------------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-organize the original dataset format\n",
    "\n",
    "## Define function & udf that need to derive columns\n",
    "def no_days_in_month(month, year):\n",
    "    if month in day_months_31: \n",
    "        return 31\n",
    "    elif month in day_months_30:\n",
    "        return 30\n",
    "    else:\n",
    "        if calendar.isleap(year):\n",
    "            return 29\n",
    "        else:\n",
    "            return 28\n",
    "        \n",
    "def day_of_week_code(day_of_week):\n",
    "    if day_of_week < 4:\n",
    "        return 1\n",
    "    elif day_of_week > 4:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def quarter_code(date, month):\n",
    "    month_31_days = [1,3,5,7,8,10,12]\n",
    "    month_30_days = [4,6,9,11]\n",
    "    if(month in month_31_days):\n",
    "        if(date in range(1,9)):\n",
    "            return 1\n",
    "        elif(date in range(9,16)):\n",
    "            return 2\n",
    "        elif(date in range(16,24)):\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    elif(month in month_30_days):\n",
    "        if(date in range(1,9)):\n",
    "            return 1\n",
    "        elif(date in range(9,16)):\n",
    "            return 2\n",
    "        elif(date in range(16,23)):\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    else: # February\n",
    "        return math.ceil(date / 4.0) \n",
    "\n",
    "def period_code(time):\n",
    "    hour = int(time[:-6])\n",
    "    if hour in range(0, 6):\n",
    "        return 1\n",
    "    elif hour in range(6, 12):\n",
    "        return 2\n",
    "    elif hour in range(12, 18):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "date = udf(lambda y, m, d : datetime.datetime(y, m ,d), DateType())\n",
    "day_of_week = udf(lambda date : int(date.weekday()), IntegerType())\n",
    "day_of_week_code_udf = udf(day_of_week_code, IntegerType())\n",
    "quarter_code_udf = udf(quarter_code, IntegerType())\n",
    "period_code_udf = udf(period_code, IntegerType())\n",
    "\n",
    "## Compute with original dataset\n",
    "df = df.withColumn(\"date\", date(df[\"ptn_yyyy\"], df[\"ptn_mm\"], df[\"ptn_dd\"]))\n",
    "df = df.withColumn(\"day_of_week\", day_of_week(df[\"date\"]))\n",
    "df = df.withColumn(\"day_of_week_code\", day_of_week_code_udf(df[\"day_of_week\"]))\n",
    "df = df.withColumn(\"quarter_code\", quarter_code_udf(df[\"ptn_dd\"], df[\"ptn_mm\"]))\n",
    "df = df.withColumn(\"period_code\", period_code_udf(df[\"txn_tm\"]))\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial user dataset\n",
    "\n",
    "## Find oldest & youngest Datetime object to calculate user's number of months.\n",
    "from pyspark.sql.functions import from_unixtime, unix_timestamp, min, max\n",
    "\n",
    "str_to_date = udf(lambda date_str : datetime.datetime.strptime(date_str[:-12], \"%Y-%m\"), DateType()) # ignore time & date\n",
    "get_user_number_of_month = udf(lambda oldest, youngest : (youngest.year - oldest.year) * 12 + (youngest.month - oldest.month) + 1, IntegerType())\n",
    "\n",
    "def get_df_with_number_of_month():\n",
    "    user_df = df.select(\"ar_id\", \"date\").withColumn(\"unix_date\", unix_timestamp(\"date\")).groupby(\"ar_id\").agg(\n",
    "                from_unixtime(min(\"unix_date\")).alias(\"min_date\"), \n",
    "                from_unixtime(max(\"unix_date\")).alias(\"max_date\"))\n",
    "    user_df = user_df.withColumn(\"oldest_month\", str_to_date(user_df[\"min_date\"]))\n",
    "    user_df = user_df.withColumn(\"youngest_month\", str_to_date(user_df[\"max_date\"]))\n",
    "    user_df = user_df.withColumn(\"user_number_of_month\", get_user_number_of_month(user_df[\"oldest_month\"], user_df[\"youngest_month\"]))\n",
    "    return user_df\n",
    "\n",
    "def initial_df():\n",
    "    user_df = get_df_with_number_of_month()\n",
    "    return user_df.join(df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"user_number_of_transfer_in\"), \"ar_id\")\\\n",
    "                    .join(df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"user_number_of_transfer_out\"), \"ar_id\")\\\n",
    "                    .join(df.filter(\"opm_tp_cd = 'CR' and txn_cd = 2\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"user_number_of_withdraw\"), \"ar_id\")\\\n",
    "                    .join(df.filter(\"opm_tp_cd = 'DR' and txn_cd = 1\").groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"user_number_of_deposit\"), \"ar_id\")\n",
    "        \n",
    "user_df = initial_df()\n",
    "user_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function for generating period & day_of_week & quarter code\n",
    "\n",
    "## Quarter code generator (quarter of the month)\n",
    "def get_df_with_quarter_code(data, col_name, agg_func, agg_col):\n",
    "    if agg_func == \"sum\":\n",
    "        return data.groupby(\"ar_id\").pivot(\"quarter_code\").sum(agg_col)\\\n",
    "                .toDF('ar_id', col_name + 'Q1', col_name + 'Q2', col_name + 'Q3', col_name + 'Q4')\n",
    "    else :\n",
    "        return data.groupby(\"ar_id\").pivot(\"quarter_code\").count()\\\n",
    "                .toDF('ar_id', col_name + 'Q1', col_name + 'Q2', col_name + 'Q3', col_name + 'Q4')\n",
    "\n",
    "## Period code generator (period of the day)\n",
    "def get_df_with_period_code(data, col_name, agg_func, agg_col):\n",
    "    if agg_func == \"sum\":\n",
    "        return data.groupby(\"ar_id\").pivot(\"period_code\").sum(agg_col)\\\n",
    "                .toDF('ar_id', col_name + 'P1', col_name + 'P2', col_name + 'P3', col_name + 'P4')\n",
    "    else :\n",
    "        return data.groupby(\"ar_id\").pivot(\"period_code\").count()\\\n",
    "                .toDF('ar_id', col_name + 'P1', col_name + 'P2', col_name + 'P3', col_name + 'P4')\n",
    "\n",
    "## Day of week code generator (Mon-Thu, Fri, Sat-Sun)\n",
    "def get_df_with_day_of_week_code(data, col_name):\n",
    "    return data.groupby(\"ar_id\").pivot(\"day_of_week_code\").count()\\\n",
    "            .toDF('ar_id', col_name + 'D1', col_name + 'D2', col_name + 'D3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction functions\n",
    "\n",
    "def noDepositBranchVisit(is_unique):\n",
    "    if is_unique:\n",
    "        data = df.select(\"ar_id\", \"svc_br_no\", \"quarter_code\").distinct()\n",
    "        grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoDepositBranchVisitUnique\")\n",
    "        return grouped_data.join(get_df_with_quarter_code(data, \"noDepositBranchVisitUnique\", \"count\", \"*\"), \"ar_id\")\n",
    "\n",
    "    else:\n",
    "        data = df.select(\"ar_id\", \"svc_br_no\", \"quarter_code\")\n",
    "        grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoDepositBranchVisit\")\n",
    "        return grouped_data.join(get_df_with_quarter_code(data, \"noDepositBranchVisit\", \"count\", \"*\"), \"ar_id\")\n",
    "\n",
    "def noDepositTransferIn(is_unique):\n",
    "    if is_unique:\n",
    "        data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").select(\"ar_id\", \"period_code\", \"day_of_week_code\", \"quarter_code\").distinct()\n",
    "        grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoTransferInUnique\")\n",
    "        return grouped_data.join(get_df_with_quarter_code(data, \"noTransferInUnique\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_period_code(data, \"noTransferInUnique\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_day_of_week_code(data, \"noTransferInUnique\"), \"ar_id\")\n",
    "    else:\n",
    "        data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\").select(\"ar_id\", \"period_code\", \"day_of_week_code\", \"quarter_code\")\n",
    "        grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoTransferIn\")\n",
    "        return grouped_data.join(get_df_with_quarter_code(data, \"noTransferIn\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_period_code(data, \"noTransferIn\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_day_of_week_code(data, \"noTransferIn\"), \"ar_id\")\n",
    "    \n",
    "def noDepositTransferOut(is_unique):\n",
    "    if is_unique:\n",
    "        data = df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").select(\"ar_id\", \"period_code\", \"day_of_week_code\", \"quarter_code\").distinct()\n",
    "        grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoTransferOutUnique\")\n",
    "        return grouped_data.join(get_df_with_quarter_code(data, \"noTransferOutUnique\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_period_code(data, \"noTransferOutUnique\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_day_of_week_code(data, \"noTransferOutUnique\"), \"ar_id\")\n",
    "    else:\n",
    "        data = df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\").select(\"ar_id\", \"period_code\", \"day_of_week_code\", \"quarter_code\")\n",
    "        grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoTransferOut\")\n",
    "        return grouped_data.join(get_df_with_quarter_code(data, \"noTransferOut\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_period_code(data, \"noTransferOut\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_day_of_week_code(data, \"noTransferOut\"), \"ar_id\")\n",
    "    \n",
    "def noDeposit(): \n",
    "    data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 2\")\n",
    "    grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoDeposit\")\n",
    "    return grouped_data.join(get_df_with_quarter_code(data, \"noDeposit\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_period_code(data, \"noDeposit\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_day_of_week_code(data, \"noDeposit\"), \"ar_id\")\n",
    "def noWithdraw(): \n",
    "    data = df.filter(\"opm_tp_cd = 'DR' and txn_cd = 1\")\n",
    "    grouped_data = data.groupby(\"ar_id\").agg({\"*\" : \"count\"}).withColumnRenamed(\"count(1)\", \"allNoWithdraw\")\n",
    "    return grouped_data.join(get_df_with_quarter_code(data, \"noWithdraw\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_period_code(data, \"noWithdraw\", \"count\", \"*\"), \"ar_id\")\\\n",
    "                .join(get_df_with_day_of_week_code(data, \"noWithdraw\"), \"ar_id\")\n",
    "def depositAmount(): \n",
    "    data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 2\")\n",
    "    grouped_data = data.groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"allDepositAmount\")\n",
    "    return grouped_data.join(get_df_with_quarter_code(data, \"depositAmount\", \"sum\", \"txn_amt\"), \"ar_id\")\n",
    "\n",
    "def withdrawAmount(): \n",
    "    data = df.filter(\"opm_tp_cd = 'DR' and txn_cd = 1\")\n",
    "    grouped_data = data.groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"allWithdrawAmount\")\n",
    "    return grouped_data.join(get_df_with_quarter_code(data, \"withdrawAmount\", \"sum\", \"txn_amt\"), \"ar_id\")\n",
    "\n",
    "def depositTransferInAmount():\n",
    "    data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\")\n",
    "    grouped_data = data.groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"allDepositTransferInAmount\")\n",
    "    return grouped_data.join(get_df_with_quarter_code(data, \"depositTransferInAmount\", \"sum\", \"txn_amt\"), \"ar_id\")\n",
    "    \n",
    "def depositTransferOutAmount():\n",
    "    data = df.filter(\"opm_tp_cd = 'DR' and txn_cd = 0\")\n",
    "    grouped_data = data.groupby(\"ar_id\").agg({\"txn_amt\" : \"sum\"}).withColumnRenamed(\"sum(txn_amt)\", \"allDepositTransferOutAmount\")\n",
    "    return grouped_data.join(get_df_with_quarter_code(data, \"depositTransferOutAmount\", \"sum\", \"txn_amt\"), \"ar_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define udf functions for ratio issues.\n",
    "ratio = udf(lambda x, y : x / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join section\n",
    "\n",
    "final_df = user_df.join(noDepositBranchVisit(is_unique=False), \"ar_id\", \"left_outer\")\\\n",
    "            .join(noDepositBranchVisit(is_unique=True), \"ar_id\", \"left_outer\")\\\n",
    "            .join(noDeposit(), \"ar_id\", \"left_outer\")\\\n",
    "            .join(noWithdraw(), \"ar_id\", \"left_outer\")\\\n",
    "            .join(depositAmount(), \"ar_id\", \"left_outer\")\\\n",
    "            .join(withdrawAmount(), \"ar_id\", \"left_outer\")\\\n",
    "            .join(noDepositTransferIn(is_unique=False), \"ar_id\", \"left_outer\")\\\n",
    "            .join(noDepositTransferIn(is_unique=True), \"ar_id\", \"left_outer\")\\\n",
    "            .join(noDepositTransferOut(is_unique=False), \"ar_id\", \"left_outer\")\\\n",
    "            .join(noDepositTransferOut(is_unique=True), \"ar_id\", \"left_outer\")\\\n",
    "            .join(depositTransferInAmount(), \"ar_id\", \"left_outer\")\\\n",
    "            .join(depositTransferOutAmount(), \"ar_id\", \"left_outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-9-3cb6d53f1a7a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-3cb6d53f1a7a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    final_df.withColumn(\"noDepositBranchVisit\", ratio(df[\"allNoDepositBranchVisit\"], df[\"user_number_of_month\"])            .withColumn(\"noDepositBranchVisitUnique\", ratio(df[\"allNoDepositBranchVisitUnique\"], df[\"user_number_of_month\"])            .withColumn(\"noDeposit\", ratio(df[\"allNoDeposit\"], df[\"user_number_of_month\"])            .withColumn(\"noWithdraw\", ratioDepositBranchVisit(df[\"allNoWithdraw\"], df[\"user_number_of_month\"])            .withColumn(\"noTransferIn\", ratio(df[\"allNoTransferIn\"], df[\"user_number_of_month\"])            .withColumn(\"noTransferOut\", ratio(df[\"allNoTransferOut\"], df[\"user_number_of_month\"])            .withColumn(\"noTransferInUnique\", ratio(df[\"allNoTransferInUnique\"], df[\"user_number_of_month\"])            .withColumn(\"noTransferOutUnique\", ratio(df[\"allNoTransferOutUnique\"], df[\"user_number_of_month\"])\\Z\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "final_df.withColumn(\"noDepositBranchVisit\", ratio(df[\"allNoDepositBranchVisit\"], df[\"user_number_of_month\"])\\\n",
    "            .withColumn(\"noDepositBranchVisitUnique\", ratio(df[\"allNoDepositBranchVisitUnique\"], df[\"user_number_of_month\"])\\\n",
    "            .withColumn(\"noDeposit\", ratio(df[\"allNoDeposit\"], df[\"user_number_of_month\"])\\\n",
    "            .withColumn(\"noWithdraw\", ratioDepositBranchVisit(df[\"allNoWithdraw\"], df[\"user_number_of_month\"])\\\n",
    "            .withColumn(\"noTransferIn\", ratio(df[\"allNoTransferIn\"], df[\"user_number_of_month\"])\\\n",
    "            .withColumn(\"noTransferOut\", ratio(df[\"allNoTransferOut\"], df[\"user_number_of_month\"])\\\n",
    "            .withColumn(\"noTransferInUnique\", ratio(df[\"allNoTransferInUnique\"], df[\"user_number_of_month\"])\\\n",
    "            .withColumn(\"noTransferOutUnique\", ratio(df[\"allNoTransferOutUnique\"], df[\"user_number_of_month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarter code example\n",
    "\n",
    "def get_df_with_quarter_code(data, col_name, agg_func, agg_col):\n",
    "    if agg_func == \"sum\":\n",
    "        return data.groupby(\"ar_id\").pivot(\"quarter_code\").sum(agg_col)\\\n",
    "                .toDF('ar_id', col_name + 'Q1', col_name + 'Q2', col_name + 'Q3', col_name + 'Q4')\n",
    "    else :\n",
    "        return data.groupby(\"ar_id\").pivot(\"quarter_code\").count()\\\n",
    "                .toDF('ar_id', col_name + 'Q1', col_name + 'Q2', col_name + 'Q3', col_name + 'Q4')\n",
    "        \n",
    "data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\")\n",
    "\n",
    "# data.groupby([\"ar_id\", \"quarter_code\"]).agg({\"*\" : \"count\"})\\\n",
    "# .withColumnRenamed(\"count(1)\", \"allNoTransferIn\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\").pivot(\"quarter_code\").sum(\"txn_amt\")\\\n",
    "# .toDF('ar_id', 'depositAmountQ1', 'depositAmountQ2', 'depositAmountQ3', 'depositAmountQ4').show()\n",
    "\n",
    "get_df_with_quarter_code(data, \"noTransferIn\", \"count\", \"*\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\").agg({\"*\" : \"count\"})\\\n",
    "# .withColumnRenamed(\"count(1)\", \"allNoTransferIn\")\\\n",
    "# .join(data.groupby(\"ar_id\").pivot(\"quarter_code\").count()\\\n",
    "# .toDF('ar_id', 'noTransferInQ1', 'noTransferInQ2', 'noTransferInQ3', 'noTransferInQ4'), \"ar_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Period code example\n",
    "            \n",
    "def get_df_with_period_code(data, col_name, agg_func, agg_col):\n",
    "    if agg_func == \"sum\":\n",
    "        return data.groupby(\"ar_id\").pivot(\"period_code\").sum(agg_col)\\\n",
    "                .toDF('ar_id', col_name + 'P1', col_name + 'P2', col_name + 'P3', col_name + 'P4')\n",
    "    else :\n",
    "        return data.groupby(\"ar_id\").pivot(\"period_code\").count()\\\n",
    "                .toDF('ar_id', col_name + 'P1', col_name + 'P2', col_name + 'P3', col_name + 'P4')\n",
    "\n",
    "data = df.filter(\"opm_tp_cd = 'CR' and txn_cd = 0\")\n",
    "\n",
    "# data.groupby(\"ar_id\").agg({\"*\" : \"count\"})\\\n",
    "# .withColumnRenamed(\"count(1)\", \"allNoDeposit\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\", \"period_code\").agg({\"*\" : \"count\"})\\\n",
    "# .withColumnRenamed(\"count(1)\", \"noDeposit\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\").pivot(\"period_code\").count()\\\n",
    "# .toDF('ar_id', 'noDepositQ1', 'noDepositQ2', 'noDepositQ3', 'noDepositQ4').show()\n",
    "\n",
    "get_df_with_period_code(data, \"noTransferIn\", \"count\", \"*\").show()\n",
    "\n",
    "# data.groupby(\"ar_id\").agg({\"*\" : \"count\"})\\\n",
    "# .withColumnRenamed(\"count(1)\", \"allNoDeposit\")\\\n",
    "# .join(data.groupby(\"ar_id\").pivot(\"period_code\").count()\\\n",
    "# .toDF('ar_id', 'noDepositP1', 'noDepositP2', 'noDepositP3', 'noDepositP4'), \"ar_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week code example\n",
    "def get_df_with_day_of_week_code(data, col_name):\n",
    "    return data.groupby(\"ar_id\").pivot(\"day_of_week_code\").count()\\\n",
    "            .toDF('ar_id', col_name + 'D1', col_name + 'D2', col_name + 'D3')\n",
    "\n",
    "get_df_with_day_of_week_code(data, \"noTransferIn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monthly example\n",
    "## Find oldest & youngest Datetime object\n",
    "from pyspark.sql.functions import from_unixtime, unix_timestamp, min, max\n",
    "\n",
    "str_to_date = udf(lambda date_str : datetime.datetime.strptime(date_str[:-12], \"%Y-%m\"), DateType()) # ignore time & date\n",
    "get_user_number_of_month = udf(lambda oldest, youngest : (youngest.year - oldest.year) * 12 + (youngest.month - oldest.month) + 1, IntegerType())\n",
    "\n",
    "\n",
    "def get_user_number_of_month(user_df):\n",
    "    user_df = df.select(\"ar_id\", \"date\").withColumn(\"unix_date\", unix_timestamp(\"date\")).groupby(\"ar_id\").agg(\n",
    "                from_unixtime(min(\"unix_date\")).alias(\"min_date\"), \n",
    "                from_unixtime(max(\"unix_date\")).alias(\"max_date\"))\n",
    "\n",
    "    # user_df.show()\n",
    "\n",
    "    user_df = user_df.withColumn(\"oldest_month\", str_to_date(user_df[\"min_date\"]))\n",
    "    user_df = user_df.withColumn(\"youngest_month\", str_to_date(user_df[\"max_date\"]))\n",
    "    user_df = user_df.withColumn(\"user_number_of_month\", get_user_number_of_month(user_df[\"oldest_month\"], user_df[\"youngest_month\"]))\n",
    "\n",
    "    # user_df.show()\n",
    "\n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
